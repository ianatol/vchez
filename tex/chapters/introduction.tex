\chapter{Introduction}
As computers become increasingly ubiquitous in our lives, the software running on them becomes even more important, but also more complex. For example, we are lucky to live at a time where computers can help us to live longer by powering advanced medical equipment \cite{med_software}, but the grave consequences of errors in the software of these devices is clear \cite{sandler2010killed}. This simultaneously increasing complexity and importance is troubling, since these two concepts are traditionally at odds. 

To confront these issues, many researchers are hard at work with the goal of ensuring reliability of software. One approach to this problem, \textit{static analysis}, aims to prove properties of programs before they are run. For example, static analysis could be performed on a program to eliminate a certain type of error from it \cite{ayewah2008using}. One approach to static analysis uses the \textit{semantics} \cite{schmidt1996programming} of a language to devise formal proofs about the ``meaning'' of a program.

However, the journey from source code written by a human to the code that is actually executed by a computer is not trivial. For many languages, source code must be translated by a tool called a \textit{compiler} to machine code that the computer can run. If the compiler makes an error in translation, any proof about the behavior of that program is now forfeit. Essentially, any proof made about the source code of a program makes the assumption that a compiler will faithfully translate its meaning to the computer.

As our programs grow in size and complexity, so too do our compilers, adding additional features and optimizations. This means that our compilers themselves are caught in the same troubling convergence of increasing complexity and importance. One natural thought is to look to prove properties about the compilers themselves. Namely, we want to prove that our compilers translate correctly --- that the meaning of any program given to them is preserved in the process of translation. For example, the CompCert project \cite{leroy2019compcert} formally verifies the correctness of a compiler for a large subset of C. If we make proofs about programs in this subset, we can be sure that their claims are preserved through the compilation process. 

In this paper, we provide a proof of correctness for a single pass of the Chez Scheme compiler \cite{dybvig2011chez}, called \textit{np-}\caname. To support and validate our reasoning, we provide two different frameworks for producing evidence of our proof. The first is a formal model of the subset of the Scheme semantics that we use to reason about the compiler pass. Built using the Coq proof assistant \cite{barras_coq_1997}, this model provides a framework for using intuitionistic logic to prove properties about Scheme and Scheme programs with a high degree of trustworthiness. This model was meant to be the basis of a mechanization of our proof, but the full mechanization ended up being outside of the scope of this thesis. The second framework provides a way of testing individual programs for semantic preservation over the \caname\ transformation. This framework, created with the Racket \cite{felleisen2015racket} language, uses an existing implementation of the Scheme formal semantics to validate our proof technique on given example programs.

We hope that this work can serve as a trustworthy proof of the correctness of this compiler pass, and more generally hope to see a future where we can wholly trust that our compilers are translating critically important programs correctly.